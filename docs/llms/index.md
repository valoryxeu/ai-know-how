---
title: Large Language Models
tags: [llms, gpt, claude, models]
---

# Large Language Models

Everything about LLMs — how they work, how to use them effectively, and how to build on top of them.

## Topics

- **Architecture** — decoder-only transformers, context windows, KV cache
- **Training** — pretraining, SFT, RLHF, DPO, constitutional AI
- **Prompt Engineering** — system prompts, few-shot, chain-of-thought, structured output
- **RAG** — retrieval-augmented generation, embeddings, vector stores, chunking
- **Fine-tuning** — when to fine-tune vs prompt, LoRA, QLoRA, data preparation
- **Evaluation** — benchmarks, evals, human preference, automated grading
- **Context Windows** — long context strategies, lost-in-the-middle, compression

## Model Landscape (2026)

| Provider | Models | Strengths |
|---|---|---|
| Anthropic | Claude 4.5/4.6 (Opus, Sonnet, Haiku) | Reasoning, safety, long context |
| OpenAI | GPT-4o, o1, o3 | Multimodal, ecosystem |
| Google | Gemini 2.x | Multimodal, integration |
| Meta | Llama 4 | Open-source, self-host |
| Mistral | Mistral Large, Codestral | European, efficient |
